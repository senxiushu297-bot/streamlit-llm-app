# -*- coding: utf-8 -*-
"""
Streamlit Ã— LangChain ã‚µãƒ³ãƒ—ãƒ«
- ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶ã®ç¨®é¡ï¼ˆç¡çœ /è‚²å…ï¼‰ã‚’é¸æŠ
- é¸æŠã«å¿œã˜ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’LLMã«æ¸¡ã—ã¦å›ç­”
- VS Code ã§å®Ÿè¡Œå¯:  ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ `streamlit run app.py`
å¿…è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:
    pip install streamlit langchain langchain-openai tiktoken python-dotenv
"""

import os
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ----------------------------
# .env èª­ã¿è¾¼ã¿
# ----------------------------
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    st.error("âŒ OPENAI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.env ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ----------------------------
# UI è¨­å®š
# ----------------------------
st.set_page_config(page_title="å°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰ Q&A (ç¡çœ /è‚²å…)", page_icon="ğŸ’¬", layout="centered")

st.title("ğŸ’¬ å°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰ Q&A")
st.caption("LangChain + Streamlit | ãƒ©ã‚¸ã‚ªã§ã€ç¡çœ ã€ã€è‚²å…ã€ã‚’é¸ã¶ã¨ã€ãã®å°‚é–€å®¶ã¨ã—ã¦å›ç­”ã—ã¾ã™ã€‚")

# ----------------------------
# ãƒ¢ãƒ‡ãƒ«è¨­å®š
# ----------------------------
model_name = st.sidebar.selectbox("ãƒ¢ãƒ‡ãƒ«", ["gpt-4o-mini", "gpt-4o", "gpt-4.1-mini"], index=0)
temperature = st.sidebar.slider("æ¸©åº¦ï¼ˆå‰µé€ æ€§ï¼‰", 0.0, 1.0, 0.2, 0.1)

# ----------------------------
# å°‚é–€å®¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
# ----------------------------
EXPERT_PROFILES = {
    "ç¡çœ ": (
        "ã‚ãªãŸã¯ç¡çœ åŒ»å­¦ã¨è¡Œå‹•ç¡çœ å­¦ã«ç²¾é€šã—ãŸå°‚é–€å®¶ã§ã™ã€‚"
        "ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã«åŸºã¥ãã€ã‚ã‹ã‚Šã‚„ã™ãã€å®Ÿè·µå¯èƒ½ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
        "ç¡çœ è¡›ç”Ÿã€æ¦‚æ—¥ãƒªã‚ºãƒ ã€å…¥çœ å›°é›£/ä¸­é€”è¦šé†’ã€ä»®çœ ã€å…‰æ›éœ²ã€ã‚«ãƒ•ã‚§ã‚¤ãƒ³ã€é‹å‹•ã€"
        "ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ»ã‚¹ãƒˆãƒ¬ã‚¹ãªã©ã‚’è€ƒæ…®ã—ã€å¿…è¦ã«å¿œã˜ã¦åŒ»ç™‚æ©Ÿé–¢å—è¨ºã®ç›®å®‰ã‚‚æç¤ºã—ã¾ã™ã€‚"
    ),
    "è‚²å…": (
        "ã‚ãªãŸã¯ç™ºé”å¿ƒç†å­¦ã¨å°å…ä¿å¥ã«è©³ã—ã„è‚²å…ã®å°‚é–€å®¶ã§ã™ã€‚"
        "å¹´é½¢ï¼ˆæœˆé½¢/å¹´é½¢ï¼‰ã«å¿œã˜ãŸç™ºé”æ®µéšã‚„å€‹æ€§ã‚’å°Šé‡ã—ã¤ã¤ã€"
        "å®‰å…¨ã§ç¾å®Ÿçš„ãªææ¡ˆã‚’æ—¥æœ¬ã®ç”Ÿæ´»ç’°å¢ƒã‚’è¸ã¾ãˆã¦è¡Œã£ã¦ãã ã•ã„ã€‚"
        "é£Ÿäº‹ã€ç¡çœ ã€ã—ã¤ã‘ã€æƒ…ç·’ã®å®‰å®šã€ä¿è‚²ãƒ»å­¦æ ¡é€£æºã€è¦ªã®ã‚»ãƒ«ãƒ•ã‚±ã‚¢ç­‰ã‚‚é…æ…®ã—ã¾ã™ã€‚"
    ),
}

# ----------------------------
# LangChain ãƒã‚§ãƒ¼ãƒ³ä½œæˆ
# ----------------------------
def build_chain(system_prompt: str) -> "Runnable":
    """ é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ³¨å…¥ã—ãŸ Chain ã‚’è¿”ã™ """
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", "{sys_msg}"),
            ("human", "{question}")
        ]
    )
    llm = ChatOpenAI(api_key=api_key, model=model_name, temperature=temperature)
    chain = prompt | llm | StrOutputParser()
    return chain

# ----------------------------
# å…¥åŠ›UI
# ----------------------------
expert = st.radio("å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š", ["ç¡çœ ", "è‚²å…"], horizontal=True)
user_text = st.text_area(
    "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆç—‡çŠ¶ã‚„çŠ¶æ³ã€å¹´é½¢ãªã©å…·ä½“çš„ã«æ›¸ãã¨ç²¾åº¦ãŒä¸ŠãŒã‚Šã¾ã™ï¼‰",
    height=140,
    placeholder="ä¾‹ï¼‰å¤œæ›´ã‹ã—ãŒç¶šã„ã¦æœèµ·ãã‚‰ã‚Œã¾ã›ã‚“ã€‚ã‚¹ãƒãƒ›ã‚’å¯ã‚‹ç›´å‰ã¾ã§è¦‹ã¦ã—ã¾ã„ã¾ã™ã€‚æ”¹å–„ç­–ã¯ï¼Ÿ",
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ä¿æŒ
if "messages" not in st.session_state:
    st.session_state.messages = []

# éå»ãƒ­ã‚°è¡¨ç¤º
for role, content in st.session_state.messages:
    with st.chat_message(role):
        st.markdown(content)

# å®Ÿè¡Œãƒœã‚¿ãƒ³ & å±¥æ­´ã‚¯ãƒªã‚¢
col1, col2 = st.columns([1, 1])
with col1:
    run = st.button("å®Ÿè¡Œ â–¶ï¸", type="primary")
with col2:
    clear = st.button("å±¥æ­´ã‚¯ãƒªã‚¢ ğŸ§¹")

if clear:
    st.session_state.messages = []
    st.experimental_rerun()

if run:
    if not user_text.strip():
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    sys_msg = EXPERT_PROFILES[expert]
    chain = build_chain(sys_msg)

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè©±ã‚’è¡¨ç¤º&ä¿å­˜
    st.session_state.messages.append(("user", user_text))
    with st.chat_message("user"):
        st.markdown(user_text)

    # æ¨è«– & è¡¨ç¤º
    with st.chat_message("assistant"):
        with st.spinner("è€ƒãˆä¸­..."):
            try:
                answer = chain.invoke({"sys_msg": sys_msg, "question": user_text})
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.stop()
            st.markdown(answer)
    # å±¥æ­´ã«è¿½åŠ 
    st.session_state.messages.append(("assistant", answer))

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.caption("Â© å°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰Q&A | LangChain + Streamlit ãƒ‡ãƒ¢")

